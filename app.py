# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kKvBx_NvqGcmsSnXHAaZG3gFMseoSi7Y
"""

import streamlit as st
import pandas as pd
import numpy as np
import io
from datetime import date, timedelta

# --- Streamlit 페이지 설정 ---
st.set_page_config(
    page_title="엑셀 데이터 처리기",
    layout="centered",
    initial_sidebar_state="auto"
)

# 제목 및 설명
st.title("📊 Excel 데이터 처리기 (스크립트 버전)")
st.markdown("제공된 Python 스크립트 로직에 따라 엑셀 파일을 읽고 데이터를 처리합니다.")
st.caption("처리할 컬럼: G, H, K, M, X (두 번째 행을 헤더로 간주하여 읽음)")

# --- 상수 및 매핑 정의 ---

# 엑셀의 컬럼 위치 (0-based 인덱스)
# G=6, H=7, K=10, M=12, X=23
# 사용자의 스크립트는 이 5개의 컬럼만 필요로 함
COLUMNS_TO_LOAD = ['G', 'H', 'K', 'M', 'X']

# pd.read_excel에 사용할 컬럼 이름 (스크립트의 iloc 인덱스를 기반으로 설정)
# G -> iloc[:, 0] -> 최종 업체명 (raw)
# H -> iloc[:, 1] -> 인계일자
# K -> iloc[:, 2] -> 위탁량
# M -> iloc[:, 3] -> 배출차량 (raw)
# X -> iloc[:, 4] -> 업체명.2
COLUMN_NAMES = [
    '업체명_RAW',        # Column G
    '인계일자',          # Column H
    '위탁량',            # Column K
    '배출차량_RAW',      # Column M
    '업체명.2'           # Column X
]

# 업체명.2 대체 맵
REPLACEMENT_MAP = {
    '수도권매립지관리공사(반입팀)': '매립지',
    '농업회사법인 석계 (주)': '석계',
    '서울물재생시설공단-서남센터': '서남',
    '서울특별시 난지 물재생센터': '난지',
    '정애영농조합법인': '정애영농',
    '인천환경공단 가좌사업소' : '가좌사업소',
    '전주리싸이클링에너지(주)-완산': '전주',
    '서울시중랑물재생센터-처리자': '중랑',
    '칠성에너지 영농조합법인':'칠성에너지'
}


# --- 핵심 처리 함수 (사용자 스크립트 기반) ---

@st.cache_data
def process_excel_data_based_on_script(uploaded_file):
    """
    업로드된 엑셀 파일을 읽고 제공된 pandas 스크립트 로직을 적용합니다.
    """
    if uploaded_file is None:
        return None, None, None, None

    # 파일을 바이트 스트림으로 변환
    data = io.BytesIO(uploaded_file.getvalue())

    try:
        # skiprows=1: 첫 번째 행(0번 인덱스) 스킵, 2번째 행(1번 인덱스)을 헤더로 읽음
        # usecols와 names를 사용하여 필요한 컬럼만 정확히 지정하고 이름 부여
        df = pd.read_excel(
            data,
            header=1, # skiprows=1과 동일한 효과 (두 번째 행을 헤더로 사용)
            usecols=COLUMNS_TO_LOAD,
            names=COLUMN_NAMES,
            dtype={'위탁량': float}
        )
    except Exception as e:
        st.error(f"엑셀 파일을 읽는 중 오류가 발생했습니다: {e}")
        return None, None, None, None

    # -----------------------------------------------------
    # --- 디버깅 정보 (처리 전 데이터의 첫 3행) ---
    debug_raw_data = df.head(3).to_string(index=False)
    # -----------------------------------------------------

    # 1. 위탁량 > 0 필터링
    df = df[df['위탁량'] > 0].copy()

    # 2. 배출차량 처리: 뒤에서 4자리 추출 및 숫자 변환
    # df2['배출차량'] = df2.iloc[:, 3].str.replace(r'^.*(.{4})$', r'\1', regex=True)
    df['배출차량'] = df['배출차량_RAW'].astype(str).str.replace(r'^.*(.{4})$', r'\1', regex=True)
    df['배출차량'] = pd.to_numeric(df['배출차량'], errors='coerce') # 에러 발생 시 NaN 처리

    # 3. 인계일자 처리: 연도와 월을 1900-01로 고정
    # df2['인계일자'] = df2['인계일자'].apply(lambda x: x.replace(year=1900, month=1))
    # datetime 객체에만 replace가 작동하므로, to_datetime으로 변환 후 처리
    def date_replace_1900_01(dt):
        if pd.isna(dt) or not isinstance(dt, (pd.Timestamp, datetime, date)):
            return pd.NaT
        return dt.replace(year=1900, month=1)

    df['인계일자'] = pd.to_datetime(df['인계일자'], errors='coerce')
    df['인계일자'] = df['인계일자'].apply(date_replace_1900_01)


    # 4. 업체명.2 처리: 매핑 대체 및 (주) 제거
    df['업체명.2'] = df['업체명.2'].replace(REPLACEMENT_MAP)
    df['업체명.2'] = df['업체명.2'].astype(str).str.replace(r'\(주\)', '', regex=True)

    # 5. 위탁량 처리: 100 미만 시 1000 곱하기
    df.loc[df['위탁량'] < 100, '위탁량'] *= 1000

    # 6. 인계일자 최종 형식 지정 및 업체명 최종 처리
    # df2['인계일자'] = pd.to_datetime(df2['인계일자']).dt.date
    df['인계일자'] = df['인계일자'].dt.date # Timezone-naive date 객체로 변환

    # df2['업체명']=df2.iloc[:,0].str.replace(r'\s+', '', regex=True)
    df['업체명'] = df['업체명_RAW'].astype(str).str.replace(r'\s+', '', regex=True) # 공백 제거

    # 7. 최종 컬럼 선택 및 순서 지정
    final_df = df[['배출차량', '인계일자', '업체명', '업체명.2', '위탁량']].reset_index(drop=True)

    if final_df.empty:
        return pd.DataFrame(), None, debug_raw_data, None

    # 8. 파일 이름 생성 (어제 날짜 기준)
    current_date = date.today()
    yesterday = current_date - timedelta(days=1)
    file_name = f'new_data_{yesterday}.xlsx'

    return final_df, file_name, debug_raw_data, yesterday


# --- Streamlit UI 구성 ---

uploaded_file = st.file_uploader(
    "1. 엑셀 파일 (.xlsx) 업로드",
    type=['xlsx'],
    help="처리할 엑셀 파일을 업로드하세요. 로직은 'skiprows=1'을 사용하여 2번째 행을 헤더로 읽습니다."
)

if uploaded_file:
    # 파일을 처리하고 결과를 받습니다.
    with st.spinner('데이터를 처리하고 있습니다...'):
        processed_df, output_filename, debug_info, yesterday = process_excel_data_based_on_script(uploaded_file)

    if processed_df is not None and not processed_df.empty:
        st.success(f"처리 완료! 총 {len(processed_df)}개의 행이 필터링 및 처리되었습니다.")

        # 디버그 정보 (처리 전 데이터의 첫 3행과 처리 후 데이터의 첫 3행)
        with st.expander("디버그 정보 확인"):
            st.subheader("RAW 데이터의 첫 3행 (읽기 직후):")
            st.text(debug_info)
            st.subheader("처리된 데이터의 첫 3행 (최종):")
            st.dataframe(processed_df.head(3), hide_index=True)

        # 2. 다운로드 버튼
        # 엑셀 파일로 변환
        excel_buffer = io.BytesIO()
        processed_df.to_excel(excel_buffer, index=False, sheet_name='Processed Data')

        st.download_button(
            label=f"2. 처리된 파일 다운로드 ({output_filename})",
            data=excel_buffer.getvalue(),
            file_name=output_filename,
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary",
            help=f"파일 이름은 {yesterday}을 기준으로 생성됩니다."
        )

    elif processed_df is not None and processed_df.empty:
        st.warning("필터링 조건(위탁량 > 0)을 만족하는 데이터가 없습니다.")
    else:
        # 파일 읽기 오류는 함수 내에서 처리됨
        pass
else:
    st.info("시작하려면 엑셀 파일을 업로드하세요. ")